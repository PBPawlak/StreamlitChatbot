# ver1 ---------------------------------------------------------------------------------------------------------------------------------------------------
# from openai import OpenAI
# import streamlit as st
# import time

# from pyexpat.errors import messages

# client = OpenAI(
#   base_url=st.secrets["BASE_URL"],
#   api_key=st.secrets["API_KEY"],
# )
# # response = client.responses.create(
# #     model="nvidia/llama-3.1-nemotron-ultra-253b-v1:free",
# #     instructions="You are a coding assistant that talks like a pirate.",
# #     input="How do I check if a Python object is an instance of a class?",
# # )

# st.write("Streamlit loves LLMs! ğŸ¤– [Build your own chat app](https://docs.streamlit.io/develop/tutorials/llms/build-conversational-apps) in minutes, then make it powerful by adding images, dataframes, or even input widgets to the chat.")

# st.caption("Note that this demo app isn't actually connected to any LLMs. Those are expensive ;)")

# # Initialize chat history
# if "messages" not in st.session_state:
#     st.session_state.messages = [{"role": "assistant", "content": "Let's start chatting! ğŸ‘‡"}]

# # Display chat messages from history on app rerun
# for message in st.session_state.messages:
#     with st.chat_message(message["role"]):
#         st.markdown(message["content"])

# # Accept user input
# if prompt := st.chat_input("What is up?"):
#     # Add user message to chat history
#     st.session_state.messages.append({"role": "user", "content": prompt})
#     # Display user message in chat message container
#     with st.chat_message("user"):
#         st.markdown(prompt)

#     # Display assistant response in chat message container
#     with st.chat_message("assistant"):
#         message_placeholder = st.empty()
#         full_response = ""
#         assistant_response = client.chat.completions.create(model=st.secrets["MODEL"], messages=st.session_state.messages)
#                 # Simulate stream of response with milliseconds delay
#         for chunk in assistant_response.choices[0].message.content.split():
#             full_response += chunk + " "
#             time.sleep(0.05)
#             # Add a blinking cursor to simulate typing
#             message_placeholder.markdown(full_response + "â–Œ")
#         message_placeholder.markdown(full_response)
#     # Add assistant response to chat history
#     st.session_state.messages.append({"role": "assistant", "content": full_response})

# ver2 ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

# from openai import OpenAI
# import streamlit as st
# import time

# # --- MISTRZ GRY RPG: SYSTEM PROMPT ---
# GAME_MASTER_PROMPT = """
# JesteÅ› Mistrzem Gry prowadzÄ…cym sesjÄ™ papierowego RPG dla jednego gracza.
# Twoim zadaniem jest:
# - UstaliÄ‡ z graczem system RPG (np. D&D, Warhammer, autorski) lub zaproponowaÄ‡ kilka do wyboru.
# - PomÃ³c w stworzeniu postaci (cechy, klasa, ekwipunek, tÅ‚o fabularne).
# - PrzedstawiÄ‡ Å›wiat gry i rozpoczÄ…Ä‡ przygodÄ™.
# - OpisywaÄ‡ sceny, zadawaÄ‡ pytania o decyzje gracza, prowadziÄ‡ narracjÄ™.
# - ZarzÄ…dzaÄ‡ mechanikÄ… gry (np. rzuty koÅ›Ä‡mi â€“ sam generuj wyniki, opisuj rezultaty).
# - TworzyÄ‡ wyzwania, spotkania, dialogi z NPC i dynamicznie reagowaÄ‡ na wybory gracza.
# - ProwadziÄ‡ walkÄ™ turowÄ…, podajÄ…c wyniki rzutÃ³w i opisujÄ…c efekty.
# - ZachÄ™caÄ‡ do kreatywnoÅ›ci i prowadziÄ‡ spÃ³jnÄ…, wciÄ…gajÄ…cÄ… historiÄ™.
# Odpowiadaj zawsze jako Mistrz Gry. Zawsze koÅ„cz wypowiedÅº pytaniem lub propozycjÄ… akcji, by gracz mÃ³gÅ‚ podjÄ…Ä‡ decyzjÄ™.
# """

# client = OpenAI(
#   base_url=st.secrets["BASE_URL"],
#   api_key=st.secrets["API_KEY"],
# )

# st.write("Streamlit loves LLMs! ğŸ¤– [Build your own chat app](https://docs.streamlit.io/develop/tutorials/llms/build-conversational-apps) in minutes, then make it powerful by adding images, dataframes, or even input widgets to the chat.")

# st.caption("Note that this demo app isn't actually connected to any LLMs. Those are expensive ;)")

# # --- INICJALIZACJA HISTORII CZATU ---
# if "messages" not in st.session_state:
#     st.session_state.messages = [
#         {"role": "assistant", "content": "Witaj podrÃ³Å¼niku! Jestem Twoim Mistrzem Gry. Czy masz ulubiony system RPG, w ktÃ³rym chcesz zagraÄ‡, czy chcesz, Å¼ebym coÅ› zaproponowaÅ‚?"}
#     ]

# # --- WYÅšWIETLANIE HISTORII CZATU ---
# for message in st.session_state.messages:
#     with st.chat_message(message["role"]):
#         st.markdown(message["content"])

# # --- FUNKCJA DO BUDOWANIA WIADOMOÅšCI Z SYSTEM PROMPTEM ---
# def get_messages():
#     return [{"role": "system", "content": GAME_MASTER_PROMPT}] + st.session_state.messages

# # --- OBSÅUGA WEJÅšCIA UÅ»YTKOWNIKA ---
# if prompt := st.chat_input("Co robisz jako gracz?"):
#     # Dodaj wiadomoÅ›Ä‡ uÅ¼ytkownika do historii
#     st.session_state.messages.append({"role": "user", "content": prompt})

#     # WyÅ›wietl wiadomoÅ›Ä‡ uÅ¼ytkownika
#     with st.chat_message("user"):
#         st.markdown(prompt)

#     # WyÅ›wietl odpowiedÅº Mistrza Gry (LLM)
#     with st.chat_message("assistant"):
#         message_placeholder = st.empty()
#         full_response = ""
#         assistant_response = client.chat.completions.create(
#             model=st.secrets["MODEL"],
#             messages=get_messages()
#         )
#         # Symulacja "pisania" odpowiedzi
#         for chunk in assistant_response.choices[0].message.content.split():
#             full_response += chunk + " "
#             time.sleep(0.05)
#             message_placeholder.markdown(full_response + "â–Œ")
#         message_placeholder.markdown(full_response)
#     # Dodaj odpowiedÅº asystenta do historii
#     st.session_state.messages.append({"role": "assistant", "content": full_response})
# 
# ver3 ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# from openai import OpenAI
# import streamlit as st
# import time

# # --- MISTRZ GRY RPG: SYSTEM PROMPT ---
# GAME_MASTER_PROMPT = """
# JesteÅ› Mistrzem Gry prowadzÄ…cym sesjÄ™ papierowego RPG dla jednego gracza.
# Twoim zadaniem jest:
# - UstaliÄ‡ z graczem system RPG (np. D&D, Warhammer, autorski) lub zaproponowaÄ‡ kilka do wyboru.
# - PomÃ³c w stworzeniu postaci (cechy, klasa, ekwipunek, tÅ‚o fabularne).
# - PrzedstawiÄ‡ Å›wiat gry i rozpoczÄ…Ä‡ przygodÄ™.
# - OpisywaÄ‡ sceny, zadawaÄ‡ pytania o decyzje gracza, prowadziÄ‡ narracjÄ™.
# - ZarzÄ…dzaÄ‡ mechanikÄ… gry (np. rzuty koÅ›Ä‡mi â€“ sam generuj wyniki, opisuj rezultaty).
# - TworzyÄ‡ wyzwania, spotkania, dialogi z NPC i dynamicznie reagowaÄ‡ na wybory gracza.
# - ProwadziÄ‡ walkÄ™ turowÄ…, podajÄ…c wyniki rzutÃ³w i opisujÄ…c efekty.
# - ZachÄ™caÄ‡ do kreatywnoÅ›ci i prowadziÄ‡ spÃ³jnÄ…, wciÄ…gajÄ…cÄ… historiÄ™.
# Odpowiadaj zawsze jako Mistrz Gry. Zawsze koÅ„cz wypowiedÅº pytaniem lub propozycjÄ… akcji, by gracz mÃ³gÅ‚ podjÄ…Ä‡ decyzjÄ™.
# """

# client = OpenAI(
#     base_url=st.secrets["BASE_URL"],
#     api_key=st.secrets["API_KEY"],
# )

# st.write("Streamlit loves LLMs! ğŸ¤– [Build your own chat app](https://docs.streamlit.io/develop/tutorials/llms/build-conversational-apps) in minutes, then make it powerful by adding images, dataframes, or even input widgets to the chat.")

# st.caption("Note that this demo app isn't actually connected to any LLMs. Those are expensive ;)")

# # --- INICJALIZACJA HISTORII CZATU ---
# if "messages" not in st.session_state:
#     st.session_state.messages = [
#         {"role": "assistant", "content": "Witaj podrÃ³Å¼niku! Jestem Twoim Mistrzem Gry. Czy masz ulubiony system RPG, w ktÃ³rym chcesz zagraÄ‡, czy chcesz, Å¼ebym coÅ› zaproponowaÅ‚?"}
#     ]

# # --- DODATKOWE ZMIENNE DO OBSÅUGI PONAWIANIA ---
# if "last_prompt" not in st.session_state:
#     st.session_state.last_prompt = None
# if "last_response_failed" not in st.session_state:
#     st.session_state.last_response_failed = False

# # --- WYÅšWIETLANIE HISTORII CZATU ---
# for message in st.session_state.messages:
#     with st.chat_message(message["role"]):
#         st.markdown(message["content"])

# # --- FUNKCJA DO BUDOWANIA WIADOMOÅšCI Z SYSTEM PROMPTEM ---
# def get_messages():
#     return [{"role": "system", "content": GAME_MASTER_PROMPT}] + st.session_state.messages

# # --- PONÃ“W PRÃ“BÄ˜ PRZYCISK ---
# def retry_last_prompt():
#     if st.session_state.last_prompt:
#         process_prompt(st.session_state.last_prompt, is_retry=True)

# # --- OBSÅUGA WEJÅšCIA UÅ»YTKOWNIKA ---
# def process_prompt(prompt, is_retry=False):
#     st.session_state.last_prompt = prompt
#     st.session_state.last_response_failed = False
#     if not is_retry:
#         st.session_state.messages.append({"role": "user", "content": prompt})

#     with st.chat_message("user"):
#         st.markdown(prompt)

#     with st.chat_message("assistant"):
#         message_placeholder = st.empty()
#         full_response = ""
#         try:
#             assistant_response = client.chat.completions.create(
#                 model=st.secrets["MODEL"],
#                 messages=get_messages()
#             )
#             content = None
#             if assistant_response and hasattr(assistant_response, "choices") and assistant_response.choices:
#                 choice = assistant_response.choices[0]
#                 if hasattr(choice, "message") and hasattr(choice.message, "content") and choice.message.content:
#                     content = choice.message.content
#                 elif hasattr(choice, "text") and choice.text:
#                     content = choice.text
#             if content:
#                 for chunk in content.split():
#                     full_response += chunk + " "
#                     time.sleep(0.05)
#                     message_placeholder.markdown(full_response + "â–Œ")
#                 message_placeholder.markdown(full_response)
#             else:
#                 st.session_state.last_response_failed = True
#                 message_placeholder.markdown("âš ï¸ Przepraszam, nie udaÅ‚o siÄ™ uzyskaÄ‡ odpowiedzi od Mistrza Gry. SprÃ³buj ponownie klikajÄ…c przycisk poniÅ¼ej.")
#                 full_response = "âš ï¸ Przepraszam, nie udaÅ‚o siÄ™ uzyskaÄ‡ odpowiedzi od Mistrza Gry. SprÃ³buj ponownie klikajÄ…c przycisk poniÅ¼ej."
#         except Exception as e:
#             st.session_state.last_response_failed = True
#             message_placeholder.markdown(f"âš ï¸ WystÄ…piÅ‚ bÅ‚Ä…d: {e}\nSprÃ³buj ponownie klikajÄ…c przycisk poniÅ¼ej.")
#             full_response = f"âš ï¸ WystÄ…piÅ‚ bÅ‚Ä…d: {e}\nSprÃ³buj ponownie klikajÄ…c przycisk poniÅ¼ej."
#     st.session_state.messages.append({"role": "assistant", "content": full_response})

# # --- GÅÃ“WNA LOGIKA ---
# prompt = st.chat_input("Co robisz jako gracz?")
# if prompt:
#     process_prompt(prompt)

# # --- PRZYCISK PONÃ“W PRÃ“BÄ˜ W PRZYPADKU NIEPOWODZENIA ---
# if st.session_state.last_response_failed:
#     st.button("ğŸ”„ PonÃ³w prÃ³bÄ™", on_click=retry_last_prompt)

# ver4 ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
from openai import OpenAI
import streamlit as st
import time
import random

# --- SYSTEM PROMPT MISTRZA GRY ---
GAME_MASTER_PROMPT = """
JesteÅ› Mistrzem Gry prowadzÄ…cym sesjÄ™ papierowego RPG dla jednego gracza.
Twoim zadaniem jest:
- OpisywaÄ‡ Å›wiat, sytuacje i wyzwania.
- PytaÄ‡ gracza o decyzje i czekaÄ‡ na jego wybÃ³r.
- JeÅ›li do rozstrzygniÄ™cia akcji potrzebny jest rzut koÅ›ciÄ…, napisz wyraÅºnie: "Czas na rzut koÅ›ciÄ…! Kliknij przycisk, aby rzuciÄ‡." i NIE opisuj jeszcze wyniku.
- Po rzucie koÅ›ciÄ… opisz rezultat akcji, biorÄ…c pod uwagÄ™ wynik rzutu (ktÃ³ry otrzymasz jako kolejnÄ… wiadomoÅ›Ä‡ od gracza, np. "Wynik rzutu: 12").
- Nigdy nie rzucaj koÅ›ciÄ… samodzielnie â€“ zawsze czekaj na wynik od gracza.
- Zawsze koÅ„cz wypowiedÅº pytaniem lub propozycjÄ… akcji.
"""

client = OpenAI(
    base_url=st.secrets["BASE_URL"],
    api_key=st.secrets["API_KEY"],
)

st.write("Streamlit RPG Game Master ğŸ¤– â€“ najpierw wybierasz akcjÄ™, potem rzucasz koÅ›ciÄ…, a AI opisuje rezultat!")

# --- INICJALIZACJA HISTORII CZATU ---
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "Witaj podrÃ³Å¼niku! Opowiedz, co chcesz zrobiÄ‡ jako pierwszy krok w przygodzie."}
    ]
if "awaiting_roll" not in st.session_state:
    st.session_state.awaiting_roll = False
if "last_roll_type" not in st.session_state:
    st.session_state.last_roll_type = "d20"
if "last_roll_prompt" not in st.session_state:
    st.session_state.last_roll_prompt = ""

# --- WYÅšWIETLANIE HISTORII CZATU ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- FUNKCJA DO BUDOWANIA WIADOMOÅšCI Z SYSTEM PROMPTEM ---
def get_messages():
    return [{"role": "system", "content": GAME_MASTER_PROMPT}] + st.session_state.messages

# --- WYSYÅANIE PROMPTU DO LLM ---
def send_to_llm(prompt):
    with st.chat_message("user"):
        st.markdown(prompt)
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        try:
            assistant_response = client.chat.completions.create(
                model=st.secrets["MODEL"],
                messages=get_messages()
            )
            content = None
            if assistant_response and hasattr(assistant_response, "choices") and assistant_response.choices:
                choice = assistant_response.choices[0]
                if hasattr(choice, "message") and hasattr(choice.message, "content") and choice.message.content:
                    content = choice.message.content
                elif hasattr(choice, "text") and choice.text:
                    content = choice.text
            if content:
                for chunk in content.split():
                    full_response += chunk + " "
                    time.sleep(0.02)
                    message_placeholder.markdown(full_response + "â–Œ")
                message_placeholder.markdown(full_response)
            else:
                message_placeholder.markdown("âš ï¸ Przepraszam, nie udaÅ‚o siÄ™ uzyskaÄ‡ odpowiedzi od Mistrza Gry.")
                full_response = "âš ï¸ Przepraszam, nie udaÅ‚o siÄ™ uzyskaÄ‡ odpowiedzi od Mistrza Gry."
        except Exception as e:
            message_placeholder.markdown(f"âš ï¸ WystÄ…piÅ‚ bÅ‚Ä…d: {e}")
            full_response = f"âš ï¸ WystÄ…piÅ‚ bÅ‚Ä…d: {e}"
    st.session_state.messages.append({"role": "assistant", "content": full_response})
    return full_response

# --- OBSÅUGA DECYZJI GRACZA ---
if not st.session_state.awaiting_roll:
    prompt = st.chat_input("Co robisz jako gracz?")
    if prompt:
        st.session_state.messages.append({"role": "user", "content": prompt})
        response = send_to_llm(prompt)
        # SprawdÅº, czy AI poprosiÅ‚o o rzut koÅ›ciÄ…
        if "Czas na rzut koÅ›ciÄ…" in response:
            st.session_state.awaiting_roll = True
            st.session_state.last_roll_type = "d20"
            st.session_state.last_roll_prompt = prompt

# --- OBSÅUGA RZUTU KOÅšCIÄ„ ---
if st.session_state.awaiting_roll:
    st.info("AI poprosiÅ‚o o rzut koÅ›ciÄ…! Kliknij poniÅ¼ej, by rzuciÄ‡.")
    if st.button("ğŸ² RzuÄ‡ koÅ›ciÄ… d20"):
        roll = random.randint(1, 20)
        st.success(f"Wynik rzutu: {roll}")
        roll_prompt = f"Wynik rzutu: {roll}"
        st.session_state.messages.append({"role": "user", "content": roll_prompt})
        send_to_llm(roll_prompt)
        st.session_state.awaiting_roll = False
        st.experimental_rerun()  # Kluczowe: natychmiast odÅ›wieÅ¼ interfejs

