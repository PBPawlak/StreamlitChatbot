# ver1 ---------------------------------------------------------------------------------------------------------------------------------------------------
# from openai import OpenAI
# import streamlit as st
# import time

# from pyexpat.errors import messages

# client = OpenAI(
#   base_url=st.secrets["BASE_URL"],
#   api_key=st.secrets["API_KEY"],
# )
# # response = client.responses.create(
# #     model="nvidia/llama-3.1-nemotron-ultra-253b-v1:free",
# #     instructions="You are a coding assistant that talks like a pirate.",
# #     input="How do I check if a Python object is an instance of a class?",
# # )

# st.write("Streamlit loves LLMs! ğŸ¤– [Build your own chat app](https://docs.streamlit.io/develop/tutorials/llms/build-conversational-apps) in minutes, then make it powerful by adding images, dataframes, or even input widgets to the chat.")

# st.caption("Note that this demo app isn't actually connected to any LLMs. Those are expensive ;)")

# # Initialize chat history
# if "messages" not in st.session_state:
#     st.session_state.messages = [{"role": "assistant", "content": "Let's start chatting! ğŸ‘‡"}]

# # Display chat messages from history on app rerun
# for message in st.session_state.messages:
#     with st.chat_message(message["role"]):
#         st.markdown(message["content"])

# # Accept user input
# if prompt := st.chat_input("What is up?"):
#     # Add user message to chat history
#     st.session_state.messages.append({"role": "user", "content": prompt})
#     # Display user message in chat message container
#     with st.chat_message("user"):
#         st.markdown(prompt)

#     # Display assistant response in chat message container
#     with st.chat_message("assistant"):
#         message_placeholder = st.empty()
#         full_response = ""
#         assistant_response = client.chat.completions.create(model=st.secrets["MODEL"], messages=st.session_state.messages)
#                 # Simulate stream of response with milliseconds delay
#         for chunk in assistant_response.choices[0].message.content.split():
#             full_response += chunk + " "
#             time.sleep(0.05)
#             # Add a blinking cursor to simulate typing
#             message_placeholder.markdown(full_response + "â–Œ")
#         message_placeholder.markdown(full_response)
#     # Add assistant response to chat history
#     st.session_state.messages.append({"role": "assistant", "content": full_response})

# ver2 ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

# from openai import OpenAI
# import streamlit as st
# import time

# # --- MISTRZ GRY RPG: SYSTEM PROMPT ---
# GAME_MASTER_PROMPT = """
# JesteÅ› Mistrzem Gry prowadzÄ…cym sesjÄ™ papierowego RPG dla jednego gracza.
# Twoim zadaniem jest:
# - UstaliÄ‡ z graczem system RPG (np. D&D, Warhammer, autorski) lub zaproponowaÄ‡ kilka do wyboru.
# - PomÃ³c w stworzeniu postaci (cechy, klasa, ekwipunek, tÅ‚o fabularne).
# - PrzedstawiÄ‡ Å›wiat gry i rozpoczÄ…Ä‡ przygodÄ™.
# - OpisywaÄ‡ sceny, zadawaÄ‡ pytania o decyzje gracza, prowadziÄ‡ narracjÄ™.
# - ZarzÄ…dzaÄ‡ mechanikÄ… gry (np. rzuty koÅ›Ä‡mi â€“ sam generuj wyniki, opisuj rezultaty).
# - TworzyÄ‡ wyzwania, spotkania, dialogi z NPC i dynamicznie reagowaÄ‡ na wybory gracza.
# - ProwadziÄ‡ walkÄ™ turowÄ…, podajÄ…c wyniki rzutÃ³w i opisujÄ…c efekty.
# - ZachÄ™caÄ‡ do kreatywnoÅ›ci i prowadziÄ‡ spÃ³jnÄ…, wciÄ…gajÄ…cÄ… historiÄ™.
# Odpowiadaj zawsze jako Mistrz Gry. Zawsze koÅ„cz wypowiedÅº pytaniem lub propozycjÄ… akcji, by gracz mÃ³gÅ‚ podjÄ…Ä‡ decyzjÄ™.
# """

# client = OpenAI(
#   base_url=st.secrets["BASE_URL"],
#   api_key=st.secrets["API_KEY"],
# )

# st.write("Streamlit loves LLMs! ğŸ¤– [Build your own chat app](https://docs.streamlit.io/develop/tutorials/llms/build-conversational-apps) in minutes, then make it powerful by adding images, dataframes, or even input widgets to the chat.")

# st.caption("Note that this demo app isn't actually connected to any LLMs. Those are expensive ;)")

# # --- INICJALIZACJA HISTORII CZATU ---
# if "messages" not in st.session_state:
#     st.session_state.messages = [
#         {"role": "assistant", "content": "Witaj podrÃ³Å¼niku! Jestem Twoim Mistrzem Gry. Czy masz ulubiony system RPG, w ktÃ³rym chcesz zagraÄ‡, czy chcesz, Å¼ebym coÅ› zaproponowaÅ‚?"}
#     ]

# # --- WYÅšWIETLANIE HISTORII CZATU ---
# for message in st.session_state.messages:
#     with st.chat_message(message["role"]):
#         st.markdown(message["content"])

# # --- FUNKCJA DO BUDOWANIA WIADOMOÅšCI Z SYSTEM PROMPTEM ---
# def get_messages():
#     return [{"role": "system", "content": GAME_MASTER_PROMPT}] + st.session_state.messages

# # --- OBSÅUGA WEJÅšCIA UÅ»YTKOWNIKA ---
# if prompt := st.chat_input("Co robisz jako gracz?"):
#     # Dodaj wiadomoÅ›Ä‡ uÅ¼ytkownika do historii
#     st.session_state.messages.append({"role": "user", "content": prompt})

#     # WyÅ›wietl wiadomoÅ›Ä‡ uÅ¼ytkownika
#     with st.chat_message("user"):
#         st.markdown(prompt)

#     # WyÅ›wietl odpowiedÅº Mistrza Gry (LLM)
#     with st.chat_message("assistant"):
#         message_placeholder = st.empty()
#         full_response = ""
#         assistant_response = client.chat.completions.create(
#             model=st.secrets["MODEL"],
#             messages=get_messages()
#         )
#         # Symulacja "pisania" odpowiedzi
#         for chunk in assistant_response.choices[0].message.content.split():
#             full_response += chunk + " "
#             time.sleep(0.05)
#             message_placeholder.markdown(full_response + "â–Œ")
#         message_placeholder.markdown(full_response)
#     # Dodaj odpowiedÅº asystenta do historii
#     st.session_state.messages.append({"role": "assistant", "content": full_response})

# ver3 ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
from openai import OpenAI
import streamlit as st
import time

# --- MISTRZ GRY RPG: SYSTEM PROMPT ---
GAME_MASTER_PROMPT = """
JesteÅ› Mistrzem Gry prowadzÄ…cym sesjÄ™ papierowego RPG dla jednego gracza.
Twoim zadaniem jest:
- UstaliÄ‡ z graczem system RPG (np. D&D, Warhammer, autorski) lub zaproponowaÄ‡ kilka do wyboru.
- PomÃ³c w stworzeniu postaci (cechy, klasa, ekwipunek, tÅ‚o fabularne).
- PrzedstawiÄ‡ Å›wiat gry i rozpoczÄ…Ä‡ przygodÄ™.
- OpisywaÄ‡ sceny, zadawaÄ‡ pytania o decyzje gracza, prowadziÄ‡ narracjÄ™.
- ZarzÄ…dzaÄ‡ mechanikÄ… gry (np. rzuty koÅ›Ä‡mi â€“ sam generuj wyniki, opisuj rezultaty).
- TworzyÄ‡ wyzwania, spotkania, dialogi z NPC i dynamicznie reagowaÄ‡ na wybory gracza.
- ProwadziÄ‡ walkÄ™ turowÄ…, podajÄ…c wyniki rzutÃ³w i opisujÄ…c efekty.
- ZachÄ™caÄ‡ do kreatywnoÅ›ci i prowadziÄ‡ spÃ³jnÄ…, wciÄ…gajÄ…cÄ… historiÄ™.
Odpowiadaj zawsze jako Mistrz Gry. Zawsze koÅ„cz wypowiedÅº pytaniem lub propozycjÄ… akcji, by gracz mÃ³gÅ‚ podjÄ…Ä‡ decyzjÄ™.
"""

client = OpenAI(
    base_url=st.secrets["BASE_URL"],
    api_key=st.secrets["API_KEY"],
)

st.write("Streamlit loves LLMs! ğŸ¤– [Build your own chat app](https://docs.streamlit.io/develop/tutorials/llms/build-conversational-apps) in minutes, then make it powerful by adding images, dataframes, or even input widgets to the chat.")

st.caption("Note that this demo app isn't actually connected to any LLMs. Those are expensive ;)")

# --- INICJALIZACJA HISTORII CZATU ---
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "Witaj podrÃ³Å¼niku! Jestem Twoim Mistrzem Gry. Czy masz ulubiony system RPG, w ktÃ³rym chcesz zagraÄ‡, czy chcesz, Å¼ebym coÅ› zaproponowaÅ‚?"}
    ]

# --- DODATKOWE ZMIENNE DO OBSÅUGI PONAWIANIA ---
if "last_prompt" not in st.session_state:
    st.session_state.last_prompt = None
if "last_response_failed" not in st.session_state:
    st.session_state.last_response_failed = False

# --- WYÅšWIETLANIE HISTORII CZATU ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- FUNKCJA DO BUDOWANIA WIADOMOÅšCI Z SYSTEM PROMPTEM ---
def get_messages():
    return [{"role": "system", "content": GAME_MASTER_PROMPT}] + st.session_state.messages

# --- PONÃ“W PRÃ“BÄ˜ PRZYCISK ---
def retry_last_prompt():
    if st.session_state.last_prompt:
        process_prompt(st.session_state.last_prompt, is_retry=True)

# --- OBSÅUGA WEJÅšCIA UÅ»YTKOWNIKA ---
def process_prompt(prompt, is_retry=False):
    st.session_state.last_prompt = prompt
    st.session_state.last_response_failed = False
    if not is_retry:
        st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        try:
            assistant_response = client.chat.completions.create(
                model=st.secrets["MODEL"],
                messages=get_messages()
            )
            content = None
            if assistant_response and hasattr(assistant_response, "choices") and assistant_response.choices:
                choice = assistant_response.choices[0]
                if hasattr(choice, "message") and hasattr(choice.message, "content") and choice.message.content:
                    content = choice.message.content
                elif hasattr(choice, "text") and choice.text:
                    content = choice.text
            if content:
                for chunk in content.split():
                    full_response += chunk + " "
                    time.sleep(0.05)
                    message_placeholder.markdown(full_response + "â–Œ")
                message_placeholder.markdown(full_response)
            else:
                st.session_state.last_response_failed = True
                message_placeholder.markdown("âš ï¸ Przepraszam, nie udaÅ‚o siÄ™ uzyskaÄ‡ odpowiedzi od Mistrza Gry. SprÃ³buj ponownie klikajÄ…c przycisk poniÅ¼ej.")
                full_response = "âš ï¸ Przepraszam, nie udaÅ‚o siÄ™ uzyskaÄ‡ odpowiedzi od Mistrza Gry. SprÃ³buj ponownie klikajÄ…c przycisk poniÅ¼ej."
        except Exception as e:
            st.session_state.last_response_failed = True
            message_placeholder.markdown(f"âš ï¸ WystÄ…piÅ‚ bÅ‚Ä…d: {e}\nSprÃ³buj ponownie klikajÄ…c przycisk poniÅ¼ej.")
            full_response = f"âš ï¸ WystÄ…piÅ‚ bÅ‚Ä…d: {e}\nSprÃ³buj ponownie klikajÄ…c przycisk poniÅ¼ej."
    st.session_state.messages.append({"role": "assistant", "content": full_response})

# --- GÅÃ“WNA LOGIKA ---
prompt = st.chat_input("Co robisz jako gracz?")
if prompt:
    process_prompt(prompt)

# --- PRZYCISK PONÃ“W PRÃ“BÄ˜ W PRZYPADKU NIEPOWODZENIA ---
if st.session_state.last_response_failed:
    st.button("ğŸ”„ PonÃ³w prÃ³bÄ™", on_click=retry_last_prompt)
